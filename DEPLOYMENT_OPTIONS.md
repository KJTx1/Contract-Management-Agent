# ğŸš€ Complete Deployment Options with LangGraph Studio

**All deployment types now include LangGraph Studio for visual RAG pipeline management**

## ğŸ¯ **Quick Reference**

| Deployment Type | Command | Studio URL | Best For |
|----------------|---------|------------|----------|
| **Local Development** | `./start-studio.sh` | http://localhost:8123 | Development, Testing |
| **Local with CLI** | `./deploy-local.sh` | http://localhost:8123 | Quick Testing |
| **Docker Studio Only** | `./deploy-studio.sh` | http://localhost:8123 | Production Studio |
| **Full Docker Stack** | `./deploy.sh` | http://localhost:8123 | Complete Solution |
| **Test All Types** | `./test-studio-all.sh` | - | Validation |

## ğŸ  **Local Development (Recommended)**

### **Quick Start**
```bash
# 1. Ensure LangSmith API key is in .env
echo "LANGSMITH_API_KEY=your-key-here" >> .env

# 2. Start Studio
./start-studio.sh

# 3. Access Studio
open http://localhost:8123
```

### **Features**
- âœ… **Fastest startup** (no Docker)
- âœ… **Hot reloading** for development
- âœ… **Native debugging** capabilities
- âœ… **Direct file access** for editing
- âœ… **CLI integration** for document management

### **Perfect For**
- ğŸ§ª Testing new features
- ğŸ› Debugging issues
- ğŸ”§ Configuration tuning
- ğŸ“š Learning the system

## ğŸ³ **Docker Deployments**

### **Studio-Only Docker**
```bash
# Lightweight Docker deployment with just Studio
./deploy-studio.sh
```

**Features:**
- âœ… **Containerized** environment
- âœ… **Production-ready** setup
- âœ… **Easy scaling** and management
- âœ… **Isolated** dependencies

### **Full Docker Stack**
```bash
# Complete solution with Studio + Web UI
./deploy.sh
```

**Features:**
- âœ… **LangGraph Studio** on port 8123
- âœ… **Web UI** on port 8000 (document management)
- âœ… **Multi-service** architecture
- âœ… **Production deployment** ready

## ğŸ¨ **LangGraph Studio Features (All Deployments)**

### **Visual Pipeline**
- ğŸ¨ **Interactive Graph**: See your 5-node RAG pipeline
- ğŸ” **Node Details**: Inspect each component
- ğŸ“Š **Data Flow**: Understand information flow
- ğŸ”§ **Live Configuration**: Adjust parameters in real-time

### **Execution Tracing**
- ğŸ” **Step-by-step Debugging**: Watch queries execute
- â±ï¸ **Performance Timing**: See bottlenecks
- ğŸ“ **Input/Output Inspection**: Debug data transformations
- âŒ **Error Tracking**: Identify and fix issues

### **Interactive Testing**
- ğŸ§ª **Query Playground**: Test queries directly
- ğŸ“Š **Real-time Results**: See immediate responses
- ğŸ”„ **Query Comparison**: Test different approaches
- ğŸ“ˆ **Performance Analysis**: Optimize your system

### **Monitoring & Analytics**
- ğŸ“Š **Response Metrics**: Track performance over time
- ğŸ“ˆ **Success Rates**: Monitor system health
- ğŸ” **Query Patterns**: Understand usage
- ğŸ¯ **Bottleneck Identification**: Find optimization opportunities

## ğŸ”§ **Configuration Requirements**

### **Required Environment Variables**
```bash
# In .env file
OPENAI_API_KEY=your-openai-key-here
LANGSMITH_API_KEY=your-langsmith-key-here
LANGSMITH_PROJECT=logistics-rag
LANGCHAIN_TRACING_V2=true
```

### **Optional Configuration**
```bash
# RAG tuning
SIMILARITY_THRESHOLD=0.3
TOP_K=5
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# Studio customization
LANGSMITH_PROJECT=your-project-name
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
```

## ğŸ¯ **Deployment Decision Matrix**

### **Choose Local Development When:**
- ğŸ§ª You're developing or testing
- ğŸ› You need to debug issues
- ğŸ”§ You want to modify code
- ğŸ“š You're learning the system
- âš¡ You want fastest startup

### **Choose Docker Studio When:**
- ğŸ­ You need production environment
- ğŸ”’ You want isolated deployment
- ğŸ“ˆ You plan to scale
- ğŸ‘¥ Multiple users will access
- ğŸŒ You need network deployment

### **Choose Full Docker Stack When:**
- ğŸ¨ You want both Studio and Web UI
- ğŸ‘¥ You have non-technical users
- ğŸ“¤ You need document upload interface
- ğŸ“Š You want comprehensive monitoring
- ğŸ¢ You're deploying for a team

## ğŸš€ **Getting Started Workflow**

### **Step 1: Setup**
```bash
# Get your API keys
# OpenAI: https://platform.openai.com/api-keys
# LangSmith: https://smith.langchain.com/

# Add to .env file
echo "OPENAI_API_KEY=your-openai-key" >> .env
echo "LANGSMITH_API_KEY=your-langsmith-key" >> .env
```

### **Step 2: Choose Deployment**
```bash
# For development
./start-studio.sh

# For production testing
./deploy-studio.sh

# For full solution
./deploy.sh
```

### **Step 3: Validate**
```bash
# Test all deployment types
./test-studio-all.sh

# Or test specific deployment
curl http://localhost:8123/health
```

### **Step 4: Use Studio**
1. Open http://localhost:8123
2. Explore the RAG pipeline graph
3. Test queries in the playground
4. Monitor execution traces
5. Optimize performance

## ğŸ“Š **Studio Usage Examples**

### **Development Workflow**
```bash
# Terminal 1: Start Studio
./start-studio.sh

# Terminal 2: Manage documents
python -m agent.cli ingest ./docs
python -m agent.cli stats

# Browser: Test and debug in Studio
# http://localhost:8123
```

### **Production Workflow**
```bash
# Deploy with Docker
./deploy-studio.sh

# Monitor via Studio
open http://localhost:8123

# Manage via CLI or API
python -m agent.cli query "production query"
```

## ğŸ” **Troubleshooting**

### **Studio Won't Start**
```bash
# Check API keys
grep LANGSMITH_API_KEY .env
grep OPENAI_API_KEY .env

# Check port availability
lsof -i :8123

# Kill existing processes
pkill -f langgraph
```

### **Studio Loads But No Graph**
```bash
# Verify graph configuration
cat langgraph.json

# Test graph import
python -c "from src.agent.graph import graph; print('OK')"
```

### **Queries Fail in Studio**
```bash
# Check documents are ingested
python -m agent.cli stats

# Test CLI query
python -m agent.cli query "test"

# Check API connectivity
python -c "import openai; print('OpenAI OK')"
```

## ğŸ‰ **Success Indicators**

Your Studio deployment is successful when:
- âœ… Studio loads at http://localhost:8123
- âœ… RAG pipeline graph is visible
- âœ… Interactive queries work
- âœ… Execution traces appear
- âœ… Performance metrics are shown
- âœ… CLI integration works
- âœ… No errors in browser console

## ğŸ“ **Quick Commands**

```bash
# Start Studio (choose one)
./start-studio.sh          # Local development
./deploy-studio.sh         # Docker studio-only
./deploy.sh                # Full Docker stack

# Test Studio
curl http://localhost:8123/health
open http://localhost:8123

# Manage System
python -m agent.cli stats
python -m agent.cli query "test"
python -m agent.cli ingest ./docs

# Debug Issues
pkill -f langgraph         # Kill processes
docker-compose logs -f     # View Docker logs
./test-studio-all.sh       # Test all deployments
```

## ğŸ¯ **Summary**

**You now have LangGraph Studio available across ALL deployment types:**

1. **âœ… Local Development**: `./start-studio.sh` - Fast, flexible, perfect for development
2. **âœ… Docker Studio**: `./deploy-studio.sh` - Production-ready, containerized
3. **âœ… Full Stack**: `./deploy.sh` - Complete solution with Web UI
4. **âœ… Testing**: `./test-studio-all.sh` - Validate all deployments

**Every deployment includes:**
- ğŸ¨ **Visual RAG Pipeline** editor
- ğŸ” **Real-time Execution** tracing
- ğŸ§ª **Interactive Query** testing
- ğŸ“Š **Performance Monitoring**
- ğŸ”§ **Debug Capabilities**

**Your RAG system is now complete with visual management across all deployment scenarios!** ğŸ‰âœ¨
