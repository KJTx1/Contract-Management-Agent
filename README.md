# ğŸ¤– Contract Management Agent

> **AI-Powered Document Intelligence for Logistics Contracts**

A sophisticated RAG (Retrieval-Augmented Generation) system built with LangGraph that transforms contract management through intelligent document processing, semantic search, and AI-powered insights.

## âœ¨ **Key Features**

- ğŸ” **Semantic Search**: Find relevant information using meaning, not just keywords
- ğŸ“„ **Document Intelligence**: Extract metadata, customer info, and key terms automatically  
- ğŸ§  **AI-Powered Answers**: Get intelligent responses with proper citations
- ğŸ¨ **LangGraph Studio**: Visual workflow design and debugging interface
- âš¡ **High Performance**: Async operations optimized for production
- ğŸŒŠ **Streaming Processing**: Process PDFs directly from OCI Object Storage (no local storage)
- ğŸ”§ **Self-Hosted**: Complete control over your data and infrastructure

## ğŸš€ **Quick Start**

### **Prerequisites**
- Python 3.11+
- OpenAI API key
- Git

### **Installation**
```bash
# Clone the repository
git clone <repository-url>
cd langraph

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e .

# Set up environment
cp .env.example .env
# Edit .env with your API keys
```

### **Start LangGraph Studio**
```bash
# Quick start
./scripts/start-studio.sh

# Or manually
source .venv/bin/activate
python -m langgraph_cli dev --port 8123
```

Visit `http://localhost:8123` to access the Studio interface.

## ğŸ“ **Project Structure**

```
â”œâ”€â”€ src/agent/                    # Core RAG implementation
â”‚   â”œâ”€â”€ standalone_graph.py     # Main RAG pipeline (Studio-compatible)
â”‚   â”œâ”€â”€ graph.py                # Graph entry point
â”‚   â”œâ”€â”€ rag_pipeline.py         # RAG workflow definition
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”œâ”€â”€ database.py             # SQLite operations
â”‚   â”œâ”€â”€ vector_operations.py    # FAISS vector store
â”‚   â”œâ”€â”€ pdf_processor.py        # Document processing
â”‚   â”œâ”€â”€ ingestion.py            # Document ingestion pipeline
â”‚   â””â”€â”€ cli.py                  # Command-line interface
â”œâ”€â”€ data/                        # Local metadata storage (SQLite + FAISS)
â”‚   â”œâ”€â”€ logistics.db            # SQLite database
â”‚   â”œâ”€â”€ faiss_index.index       # FAISS vector index
â”‚   â””â”€â”€ pdfs/                   # Sample PDF files (dev only - production uses OCI streaming)
â”œâ”€â”€ scripts/                     # Deployment and utility scripts
â”‚   â”œâ”€â”€ start-studio.sh        # Studio startup script
â”‚   â”œâ”€â”€ deploy-local.sh        # Local deployment
â”‚   â””â”€â”€ deploy-studio.sh       # Studio deployment
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ README.md              # This file
â”‚   â”œâ”€â”€ ARCHITECTURE.md        # Technical architecture
â”‚   â””â”€â”€ STUDIO_SETUP_GUIDE.md  # Studio setup guide
â”œâ”€â”€ docker/                      # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile             # Main application
â”‚   â”œâ”€â”€ Dockerfile.studio      # Studio-specific
â”‚   â””â”€â”€ docker-compose.yml     # Multi-container setup
â”œâ”€â”€ config/                      # Configuration files
â”‚   â””â”€â”€ langgraph.json         # LangGraph configuration
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ unit_tests/             # Unit tests
â”‚   â”œâ”€â”€ integration_tests/      # Integration tests
â”‚   â””â”€â”€ test_system_integration.py # End-to-end system test
â””â”€â”€ pyproject.toml              # Python dependencies
```

## ğŸ”§ **Configuration**

### **Environment Variables**
Create a `.env` file with:
```bash
# API Keys
OPENAI_API_KEY=your_openai_api_key_here
COHERE_API_KEY=your_cohere_api_key_here  # Optional

# LangSmith (Optional)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=contract-management-agent

# OCI Configuration (Required for Object Storage)
OCI_CONFIG_FILE=~/.oci/config
OCI_PROFILE=DEFAULT
OCI_BUCKET_NAME=contract-documents

# Embedding Configuration
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini

# Retrieval Configuration
TOP_K=20
SIMILARITY_THRESHOLD=0.3
```

**Copy the example configuration:**
```bash
cp config/env.example .env
# Edit .env with your actual API keys and OCI configuration
```

### **OCI Setup**
1. **Install OCI CLI**: `pip install oci`
2. **Configure OCI**: Set up `~/.oci/config` file or environment variables
3. **Create Bucket**: Create an OCI Object Storage bucket
4. **Set Environment**: Configure `OCI_BUCKET_NAME` in your `.env` file

**OCI Configuration Options:**
- **Config File**: `~/.oci/config` (recommended)
- **Environment Variables**: Set OCI_* variables directly
- **Instance Principal**: For OCI compute instances

## ğŸ“Š **Sample Data**

The system comes with 5 sample logistics contracts:
- **UrbanWear Group Ltd.** - Fashion logistics contract
- **HealthFirst Pharmaceuticals Inc.** - Pharmaceutical logistics
- **Bright Manufacturing Inc.** - Manufacturing logistics
- **TechFlow Solutions** - Technology logistics
- **Global Logistics Solutions** - General logistics services

## ğŸ¯ **Usage**

### **Adding New Documents**
```bash
# Place PDF files anywhere and ingest them
cp your-contract.pdf ./your-contract.pdf

# Run ingestion pipeline
python -m src.agent.cli ingest --source your-contract.pdf

# Restart Studio to see changes
./scripts/start-studio.sh
```

### **Querying Documents**
```bash
# Command line interface
python -m src.agent.cli query "Tell me about UrbanWear Group Ltd."

# Or use Studio interface at http://localhost:8123
```

### **System Statistics**
```bash
# Check system status
python -m src.agent.cli stats
```

## ğŸ—ï¸ **Production Architecture (OCI)**

### **Cloud Storage**
- **OCI Object Storage**: Primary document storage (âœ… Implemented)
- **OCI Vector Database**: Production vector store (Future enhancement)
- **OCI Database**: Metadata and document tracking (Future enhancement)

### **Current Implementation**
- **Document Storage**: OCI Object Storage with local fallback
- **Vector Store**: FAISS (local) with OCI streaming for documents
- **Database**: SQLite (local) with OCI URLs for document references

### **OCI Setup Requirements**
1. **OCI Account**: Oracle Cloud Infrastructure account
2. **Object Storage Bucket**: Create a bucket for document storage
3. **API Keys**: Generate OCI API keys and configure authentication
4. **Configuration**: Set up OCI config file or environment variables

### **Development vs Production**
- **Development**: Local `data/` directory with SQLite + FAISS + OCI streaming
- **Production**: OCI object storage + FAISS + SQLite (hybrid approach)

## ğŸ§ª **Testing**

```bash
# Run all unit and integration tests
python -m pytest tests/ -v

# Run specific test suite
python -m pytest tests/unit_tests/
python -m pytest tests/integration_tests/

# Run system integration test (end-to-end validation)
python tests/test_system_integration.py

# Or use quick-start script
./quick-start.sh test        # Unit/integration tests
./quick-start.sh system      # System integration test
```

## ğŸš€ **Deployment Options**

### **Local Development**
```bash
./scripts/start-studio.sh
```

### **Docker Deployment**
```bash
# Build and run with Docker Compose
cd docker/
docker-compose up -d
```

### **Production Deployment**
```bash
# Deploy to production environment
./scripts/deploy.sh
```

## ğŸ” **Technical Deep Dive**

### **RAG Pipeline**
1. **Document Ingestion**: PDF â†’ Text â†’ Chunks â†’ Embeddings
2. **Vector Storage**: FAISS index for fast similarity search
3. **Metadata Storage**: SQLite for document relationships
4. **Query Processing**: Embedding â†’ Search â†’ Context â†’ LLM
5. **Response Generation**: AI-powered answers with citations

### **Key Technologies**
- **LangGraph**: Workflow orchestration
- **OpenAI**: Embeddings and LLM generation
- **FAISS**: Vector similarity search
- **SQLite**: Metadata and document tracking
- **PyPDF2**: PDF text extraction

## ğŸ“ˆ **Performance**

- **Embedding Generation**: ~2-3 seconds per document
- **Vector Search**: <100ms for similarity queries
- **LLM Response**: ~3-5 seconds for complex queries
- **Studio Interface**: Real-time workflow visualization

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ **Support**

- **Documentation**: Check the `docs/` directory
- **Issues**: Create a GitHub issue
- **Discussions**: Use GitHub Discussions for questions

---

**Built with â¤ï¸ using LangGraph, OpenAI, and modern AI technologies**